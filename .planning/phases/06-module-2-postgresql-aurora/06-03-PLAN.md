---
phase: 06-module-2-postgresql-aurora
plan: 03
type: execute
wave: 1
depends_on: []
files_modified:
  - src/content/course/02-module-2/06-snapshot-strategies.mdx
  - src/content/course/02-module-2/07-incremental-snapshot-lab.mdx
autonomous: true

must_haves:
  truths:
    - "Students can choose between initial and incremental snapshot strategies based on table size"
    - "Students understand incremental snapshots run parallel to streaming (no blocking)"
    - "Students can create signaling table and trigger incremental snapshot via INSERT"
    - "Students can tune chunk size based on row width and memory"
  artifacts:
    - path: "src/content/course/02-module-2/06-snapshot-strategies.mdx"
      provides: "Snapshot mode comparison, use cases, decision framework"
      min_lines: 160
    - path: "src/content/course/02-module-2/07-incremental-snapshot-lab.mdx"
      provides: "Hands-on lab with signaling table, snapshot triggering, monitoring"
      min_lines: 200
  key_links:
    - from: "06-snapshot-strategies.mdx"
      to: "07-incremental-snapshot-lab.mdx"
      via: "Theory lesson followed by hands-on practice"
    - from: "07-incremental-snapshot-lab.mdx"
      to: "debezium_signal table"
      via: "INSERT triggers snapshot, connector reads signal and starts chunking"
---

<objective>
Create snapshot strategy lessons covering initial vs incremental snapshots and a hands-on lab for incremental snapshot configuration.

Purpose: Large table snapshotting is a common production challenge. Traditional snapshots block streaming and cause downtime. Incremental snapshots (Debezium 1.6+) solve this but require understanding of signaling tables, chunk tuning, and schema change coordination.

Output: One theory lesson on snapshot strategies (06) and one hands-on lab (07) with signaling table setup, snapshot triggering, and Python consumer to monitor snapshot events.
</objective>

<execution_context>
@/Users/levoely/.claude/get-shit-done/workflows/execute-plan.md
@/Users/levoely/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/06-module-2-postgresql-aurora/06-RESEARCH.md

# Lab environment reference
@labs/README.md

# Established content patterns
@src/content/course/01-module-1/04-first-connector.mdx
@src/content/course/01-module-1/05-python-consumer.mdx
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Snapshot Strategies lesson</name>
  <files>src/content/course/02-module-2/06-snapshot-strategies.mdx</files>
  <action>
Create comprehensive lesson on snapshot strategies (MOD2-06):

**Structure:**
1. Why snapshots matter - initial data sync before streaming begins
2. Snapshot modes comparison: initial, initial_only, never, when_needed, always
3. Traditional snapshot limitations - blocks streaming, locks tables, no resumability
4. Incremental snapshots (Debezium 1.6+) - parallel to streaming, chunk-based, resumable
5. Decision framework: When to use which strategy
6. Chunk size tuning based on table characteristics

**Include:**
- Comparison table: All snapshot modes with use cases
- Mermaid diagram: Traditional snapshot timeline (blocks streaming)
- Mermaid diagram: Incremental snapshot timeline (parallel to streaming)
- Decision flowchart: Choose snapshot strategy based on table size, downtime tolerance
- Chunk size tuning formula from RESEARCH.md:
  - chunk_size = (target_chunk_memory_mb * 1024) / average_row_size_kb
  - Examples: wide JSONB (500-1000), narrow logs (8192-16384), standard OLTP (2048-4096)

**Critical teaching points (from RESEARCH.md):**
- snapshot.mode=always is ANTI-PATTERN in production (blocks streaming)
- Incremental snapshots use op='r' (read) events with source.snapshot='true'
- Schema changes during snapshot cause failures - coordinate maintenance windows

**Style:**
- Russian explanatory text, English configuration examples
- Frontmatter: title, description, order: 6, difficulty: intermediate, duration: 25min, topics: [snapshot-strategies, incremental-snapshot, chunk-tuning]
  </action>
  <verify>
- File exists at src/content/course/02-module-2/06-snapshot-strategies.mdx
- `npm run build` passes without errors
- File contains snapshot mode comparison table
- File has 160+ lines
- File mentions chunk size tuning
  </verify>
  <done>Students can select appropriate snapshot strategy based on requirements, understand incremental snapshot benefits, and calculate appropriate chunk sizes</done>
</task>

<task type="auto">
  <name>Task 2: Create Incremental Snapshot Lab lesson</name>
  <files>src/content/course/02-module-2/07-incremental-snapshot-lab.mdx</files>
  <action>
Create hands-on lab for incremental snapshot practice (MOD2-07):

**Structure:**
1. Lab objectives - trigger and monitor incremental snapshot
2. Prerequisites - running lab environment from Module 1
3. Step 1: Create signaling table (debezium_signal)
4. Step 2: Create large test table with sample data (10k+ rows)
5. Step 3: Deploy connector with incremental snapshot configuration
6. Step 4: Trigger incremental snapshot via INSERT
7. Step 5: Monitor snapshot progress with Python consumer
8. Step 6: Stop and resume snapshot (demonstrate resumability)
9. Optional: Filtered snapshot (additional-conditions)

**Include:**
- Signaling table DDL from RESEARCH.md
- Connector config JSON with signal.data.collection, incremental.snapshot.chunk.size
- INSERT statements to trigger snapshot (execute-snapshot type)
- Python consumer code to detect snapshot events (source.snapshot='true', op='r')
- INSERT statement to stop snapshot (stop-snapshot type)
- Filtered snapshot example (order_date >= '2025-01-01')

**Lab-specific details:**
- Use existing lab PostgreSQL (port 5433 external, 5432 internal)
- Create orders_large table with 10,000 sample rows
- Use smaller chunk_size (512) to demonstrate chunking visibly
- Show snapshot progress in consumer output

**Style:**
- Russian explanatory text, English code/SQL/JSON
- Step-by-step instructions with clear verification at each step
- Frontmatter: title, description, order: 7, difficulty: advanced, duration: 45min, topics: [incremental-snapshot, signaling-table, hands-on-lab, python-consumer]
  </action>
  <verify>
- File exists at src/content/course/02-module-2/07-incremental-snapshot-lab.mdx
- `npm run build` passes without errors
- File contains signaling table DDL
- File contains Python consumer code
- File has 200+ lines
- File includes execute-snapshot and stop-snapshot examples
  </verify>
  <done>Students can execute a complete incremental snapshot workflow: create signaling table, configure connector, trigger snapshot, monitor with Python, and demonstrate stop/resume capability</done>
</task>

</tasks>

<verification>
After all tasks complete:
1. Two lesson files exist (06-snapshot-strategies.mdx, 07-incremental-snapshot-lab.mdx)
2. `npm run build` passes without errors
3. Each file has proper frontmatter with order, difficulty, duration
4. Mermaid diagrams render correctly
5. Lab instructions reference correct Docker ports (5433 external)
6. Python code uses confluent-kafka (not kafka-python) per project conventions
</verification>

<success_criteria>
- 2 MDX files created in src/content/course/02-module-2/
- Total 360+ lines across both files
- 3+ Mermaid diagrams total
- Both files pass content collection validation
- Build completes without errors
- Lab is executable with existing Docker Compose environment
- Python consumer code detects snapshot vs streaming events correctly
</success_criteria>

<output>
After completion, create `.planning/phases/06-module-2-postgresql-aurora/06-03-SUMMARY.md`
</output>
