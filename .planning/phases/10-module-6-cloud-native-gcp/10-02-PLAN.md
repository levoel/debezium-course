---
phase: 10-module-6-cloud-native-gcp
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - src/content/course/06-module-6/03-iam-workload-identity.mdx
  - src/content/course/06-module-6/04-dataflow-bigquery.mdx
autonomous: true

must_haves:
  truths:
    - "Students can configure Workload Identity for secure GCP authentication"
    - "Students can deploy Dataflow template for CDC to BigQuery replication"
    - "Students understand IAM roles needed for CDC pipeline components"
  artifacts:
    - path: "src/content/course/06-module-6/03-iam-workload-identity.mdx"
      provides: "IAM and Workload Identity configuration lesson"
      contains: "iam.gke.io/gcp-service-account"
    - path: "src/content/course/06-module-6/04-dataflow-bigquery.mdx"
      provides: "Dataflow CDC to BigQuery lesson"
      contains: "gcloud dataflow flex-template run"
  key_links:
    - from: "lesson-03"
      to: "lesson-04"
      via: "IAM roles enable Dataflow access to Pub/Sub and BigQuery"
      pattern: "roles/pubsub|roles/bigquery"
---

<objective>
Create lessons covering GCP security (IAM/Workload Identity) and data pipeline (Dataflow to BigQuery) for CDC.

Purpose: Complete the data path from Pub/Sub to BigQuery using managed GCP services with proper security configuration. These lessons teach enterprise-grade patterns for authenticating CDC workloads and replicating data to the data warehouse.

Output: Two MDX lessons covering Workload Identity for secure authentication and Dataflow templates for BigQuery replication.
</objective>

<execution_context>
@/Users/levoely/.claude/get-shit-done/workflows/execute-plan.md
@/Users/levoely/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/10-module-6-cloud-native-gcp/10-RESEARCH.md

Reference for content patterns:
@src/content/course/05-module-5/01-advanced-python-consumer.mdx
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create IAM and Workload Identity lesson</name>
  <files>src/content/course/06-module-6/03-iam-workload-identity.mdx</files>
  <action>
Create MDX lesson covering secure GCP authentication for CDC workloads.

**Frontmatter:**
```yaml
title: "IAM и Workload Identity для CDC Pipeline"
description: "Безопасная аутентификация Debezium Server и других компонентов CDC в GCP"
order: 3
difficulty: "intermediate"
estimatedTime: 35
topics: ["IAM", "Workload Identity", "GKE", "Security", "Service Accounts"]
prerequisites: ["module-6/02-debezium-server-pubsub"]
```

**Content structure:**

1. **Introduction** - Authentication in GCP CDC pipelines
   - Components that need GCP access: Debezium Server, Dataflow, Cloud Run
   - Traditional approach: Service account key files (anti-pattern)
   - Modern approach: Workload Identity Federation
   - Why keys are dangerous: leakage risk, rotation burden, audit gaps

2. **IAM Roles for CDC Pipeline**
   - Table of roles per component:
     | Component | Required Roles |
     |-----------|---------------|
     | Debezium Server | roles/pubsub.publisher |
     | Dataflow Job | roles/pubsub.subscriber, roles/bigquery.dataEditor |
     | Cloud Run | roles/pubsub.subscriber |
   - Principle of least privilege explanation

3. **Creating GCP Service Account**
   - gcloud commands:
     ```bash
     # Create service account for Debezium Server
     gcloud iam service-accounts create debezium-server-sa \
       --display-name="Debezium Server CDC"

     # Grant Pub/Sub Publisher role
     gcloud projects add-iam-policy-binding PROJECT_ID \
       --member="serviceAccount:debezium-server-sa@PROJECT_ID.iam.gserviceaccount.com" \
       --role="roles/pubsub.publisher"
     ```

4. **Workload Identity for GKE** (primary pattern)
   - Concept explanation: K8s Service Account <-> GCP Service Account binding
   - Mermaid diagram: Pod -> K8s SA -> Workload Identity -> GCP SA -> IAM
   - Step-by-step setup:
     ```yaml
     # Kubernetes Service Account with annotation
     apiVersion: v1
     kind: ServiceAccount
     metadata:
       name: debezium-server
       namespace: cdc
       annotations:
         iam.gke.io/gcp-service-account: debezium-server-sa@PROJECT_ID.iam.gserviceaccount.com
     ```
   - Binding command:
     ```bash
     gcloud iam service-accounts add-iam-policy-binding \
       debezium-server-sa@PROJECT_ID.iam.gserviceaccount.com \
       --role=roles/iam.workloadIdentityUser \
       --member="serviceAccount:PROJECT_ID.svc.id.goog[cdc/debezium-server]"
     ```

5. **Workload Identity for Cloud Run**
   - Simpler: directly attach service account to Cloud Run service
   - gcloud command:
     ```bash
     gcloud run services update cdc-processor \
       --service-account=cdc-processor-sa@PROJECT_ID.iam.gserviceaccount.com
     ```

6. **Secret Manager for Database Credentials**
   - Creating secrets:
     ```bash
     echo -n "password123" | gcloud secrets create db-password --data-file=-
     ```
   - Granting access:
     ```bash
     gcloud secrets add-iam-policy-binding db-password \
       --member="serviceAccount:debezium-server-sa@PROJECT_ID.iam.gserviceaccount.com" \
       --role="roles/secretmanager.secretAccessor"
     ```
   - Mounting in Kubernetes (CSI driver approach)

7. **Verifying Authentication**
   - Test Workload Identity from pod:
     ```bash
     kubectl exec -it debezium-server-xxx -- \
       gcloud auth list
     ```
   - Common issues: namespace mismatch, annotation typo, binding not propagated

8. **Anti-Patterns to Avoid**
   - Service account key files in git/containers
   - Overly permissive roles (roles/owner, roles/editor)
   - Shared service accounts across environments

Include Mermaid diagram showing complete authentication flow from Pod to GCP APIs.
  </action>
  <verify>
File exists at src/content/course/06-module-6/03-iam-workload-identity.mdx
Content includes Kubernetes ServiceAccount YAML with iam.gke.io/gcp-service-account annotation
Content includes gcloud iam service-accounts commands
Content includes Workload Identity binding command
Content includes Secret Manager integration
Frontmatter has all required fields
  </verify>
  <done>
Lesson covers secure GCP authentication with Workload Identity, IAM role assignments, and Secret Manager integration for database credentials.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create Dataflow to BigQuery lesson</name>
  <files>src/content/course/06-module-6/04-dataflow-bigquery.mdx</files>
  <action>
Create MDX lesson covering Dataflow CDC template for BigQuery replication.

**Frontmatter:**
```yaml
title: "Dataflow Template: CDC в BigQuery"
description: "Использование managed Dataflow template для репликации CDC данных из Pub/Sub в BigQuery"
order: 4
difficulty: "advanced"
estimatedTime: 40
topics: ["Dataflow", "BigQuery", "Pub/Sub", "CDC Replication", "Data Warehouse"]
prerequisites: ["module-6/02-debezium-server-pubsub", "module-6/03-iam-workload-identity"]
```

**Content structure:**

1. **Introduction** - CDC to Data Warehouse pattern
   - Why BigQuery as CDC destination: analytics, ML, reporting
   - Architecture: Pub/Sub -> Dataflow -> BigQuery
   - Template vs Custom pipeline tradeoffs
   - Mermaid diagram of complete flow

2. **Dataflow CDC Template Overview**
   - Google's managed template: handles schema evolution, DDL callbacks, MERGE operations
   - Two-table pattern: changelog (staging) + replica
   - Template URL: `gs://dataflow-templates-REGION/latest/flex/Mysql_Change_Data_Capture_to_BigQuery`
   - Note: Template named for MySQL but compatible with Debezium PostgreSQL events (same format)

3. **Pre-requisites Before Launch**
   - Pub/Sub subscriptions (one per topic):
     ```bash
     gcloud pubsub subscriptions create cdc.public.orders-sub \
       --topic=cdc.public.orders \
       --ack-deadline=60
     ```
   - BigQuery datasets:
     ```bash
     bq mk --dataset cdc_staging
     bq mk --dataset cdc_replica
     ```
   - IAM: Dataflow worker SA needs:
     - roles/pubsub.subscriber
     - roles/bigquery.dataEditor
     - roles/dataflow.worker

4. **Launching the Dataflow Job**
   - Complete gcloud command from research:
     ```bash
     gcloud dataflow flex-template run "cdc-to-bigquery-$(date +%Y%m%d-%H%M%S)" \
       --template-file-gcs-location gs://dataflow-templates-us-central1/latest/flex/Mysql_Change_Data_Capture_to_BigQuery \
       --region us-central1 \
       --parameters \
     inputSubscriptions="projects/PROJECT/subscriptions/cdc.public.orders-sub",\
     changeLogDataset="cdc_staging",\
     replicaDataset="cdc_replica",\
     updateFrequencySecs=60,\
     useStorageWriteApi=true,\
     useStorageWriteApiAtLeastOnce=false
     ```
   - Explain each parameter in detail

5. **Understanding the Output Tables**
   - Changelog table structure:
     - All CDC fields (before, after, op, source)
     - Metadata: _metadata_timestamp, _metadata_read_timestamp
   - Replica table: current state (latest version per primary key)
   - MERGE operation explained: every `updateFrequencySecs`

6. **Exactly-Once vs At-Least-Once**
   - `useStorageWriteApiAtLeastOnce=false` -> exactly-once (costs more)
   - `useStorageWriteApiAtLeastOnce=true` -> at-least-once (MERGE handles duplicates)
   - Cost optimization: at-least-once often sufficient since MERGE deduplicates
   - Reference Module 5 exactly-once concepts

7. **Monitoring Dataflow Job**
   - Console: Dataflow > Jobs > Job details
   - Key metrics: Elements processed, system lag, worker utilization
   - Alerting on lag:
     ```yaml
     metric.type="dataflow.googleapis.com/job/system_lag"
     ```

8. **Schema Evolution Handling**
   - How template handles new columns: automatic BigQuery schema update
   - Limitations: column type changes, column removals
   - Reference Module 4 schema evolution concepts

9. **Alternative: Custom Dataflow Pipeline**
   - When to build custom: complex transformations, non-standard schema
   - Apache Beam Python/Java options
   - Brief code example (Python Beam for context)

Include Mermaid diagram showing: Pub/Sub -> Dataflow (MERGE) -> BigQuery (staging + replica)
  </action>
  <verify>
File exists at src/content/course/06-module-6/04-dataflow-bigquery.mdx
Content includes gcloud dataflow flex-template run command
Content includes two-dataset pattern (staging + replica)
Content includes exactly-once vs at-least-once explanation
Content includes monitoring guidance
Frontmatter has all required fields
  </verify>
  <done>
Lesson covers Dataflow CDC template deployment with complete gcloud commands, output table patterns, exactly-once semantics, and monitoring guidance.
  </done>
</task>

</tasks>

<verification>
- Both lessons created in src/content/course/06-module-6/ directory
- Lesson 03 covers IAM roles table and Workload Identity setup (MOD6-03)
- Lesson 04 covers Dataflow template launch and BigQuery patterns (MOD6-04)
- Prerequisites correctly chain: 02 -> 03 -> 04
- Research patterns incorporated: Workload Identity YAML, Dataflow template command
- Security best practices emphasized (no key files, least privilege)
</verification>

<success_criteria>
- MOD6-03 requirement covered by lesson 03 (IAM and Workload Identity)
- MOD6-04 requirement covered by lesson 04 (Dataflow templates for CDC in BigQuery)
- Students can configure secure authentication for all CDC components
- Students can deploy Dataflow job for Pub/Sub to BigQuery replication
</success_criteria>

<output>
After completion, create `.planning/phases/10-module-6-cloud-native-gcp/10-02-SUMMARY.md`
</output>
