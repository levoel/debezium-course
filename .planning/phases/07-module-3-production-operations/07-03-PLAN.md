---
phase: 07-module-3-production-operations
plan: 03
type: execute
wave: 1
depends_on: []
files_modified:
  - src/content/course/03-module-3/05-wal-bloat-heartbeat.mdx
  - src/content/course/03-module-3/06-connector-scaling-tasks.mdx
  - src/content/course/03-module-3/07-disaster-recovery-procedures.mdx
autonomous: true

must_haves:
  truths:
    - "Students can configure heartbeat.action.query with pg_logical_emit_message() for slot advancement"
    - "Students understand PostgreSQL connector is LIMITED TO SINGLE TASK (tasks.max has no effect)"
    - "Students can execute offset backup using kafka-console-consumer or REST API"
    - "Students know actual scaling strategies: multiple connectors, downstream parallelization"
    - "Students can use Kafka Connect REST API for offset management (3.6+)"
  artifacts:
    - path: "src/content/course/03-module-3/05-wal-bloat-heartbeat.mdx"
      provides: "Multi-layer WAL defense, heartbeat configuration, slot monitoring"
      min_lines: 200
    - path: "src/content/course/03-module-3/06-connector-scaling-tasks.mdx"
      provides: "Task model truth, scaling strategies, performance tuning"
      min_lines: 180
    - path: "src/content/course/03-module-3/07-disaster-recovery-procedures.mdx"
      provides: "Offset backup, restoration, slot recreation procedures"
      min_lines: 200
  key_links:
    - from: "05-wal-bloat-heartbeat.mdx"
      to: "Phase 6 max_slot_wal_keep_size content"
      via: "Heartbeat complements max_slot_wal_keep_size for WAL defense"
    - from: "06-connector-scaling-tasks.mdx"
      to: "07-disaster-recovery-procedures.mdx"
      via: "Scaling multiple connectors -> need DR for each"
---

<objective>
Create operational procedures lessons covering WAL bloat prevention, connector scaling reality, and disaster recovery.

Purpose: These lessons teach the "how to operate" skills - preventing common failures (WAL bloat), understanding scaling constraints (single-task limitation), and recovering from disasters (offset restoration). Critical for production readiness.

Output: Three MDX lessons (05, 06, 07) covering MOD3-05 (heartbeat/WAL), MOD3-06 (scaling), and MOD3-07 (DR procedures).
</objective>

<execution_context>
@/Users/levoely/.claude/get-shit-done/workflows/execute-plan.md
@/Users/levoely/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/07-module-3-production-operations/07-RESEARCH.md

# WAL management foundation from Phase 6
@src/content/course/02-module-2/02-replication-slots-lifecycle.mdx
@src/content/course/02-module-2/03-wal-configuration-tuning.mdx

# Lab infrastructure
@labs/docker-compose.yml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create WAL Bloat and Heartbeat lesson</name>
  <files>src/content/course/03-module-3/05-wal-bloat-heartbeat.mdx</files>
  <action>
Create comprehensive lesson on WAL bloat prevention through heartbeat configuration (MOD3-05):

**Structure:**
1. WAL bloat problem recap (link to Phase 6 content):
   - Slots prevent WAL deletion until consumed
   - Low-traffic tables = slot never advances = WAL accumulates
   - Disk exhaustion -> database read-only -> outage
2. Multi-layer WAL defense stack:
   - Layer 1: max_slot_wal_keep_size (PostgreSQL parameter, covered in Phase 6)
   - Layer 2: heartbeat configuration (Debezium connector)
   - Layer 3: Monitoring and alerting (covered in Plan 07-02)
   - Layer 4: Operational runbooks (this lesson)
3. Heartbeat configuration deep dive:
   - heartbeat.interval.ms = 10000 (10s, prior decision for Aurora failover)
   - heartbeat.action.query options:
     - PostgreSQL 14+: SELECT pg_logical_emit_message(false, 'heartbeat', now()::varchar)
     - PostgreSQL 13-: UPDATE heartbeat table approach (legacy)
   - Why pg_logical_emit_message() is preferred (no table needed, cleaner)
4. Monitoring retained WAL per slot:
   - pg_replication_slots query with retained_wal calculation
   - Alert thresholds: >1GB warning, >5GB critical
   - wal_status column interpretation ('reserved' ok, 'lost' = problem)
5. Lab exercise: Configure heartbeat, verify slot advancement during idle period

**Include:**
- Mermaid diagram: Heartbeat flow (Debezium -> pg_logical_emit_message -> WAL advance -> slot restart_lsn moves)
- Complete connector config with heartbeat settings
- SQL monitoring query from RESEARCH.md (comprehensive slot health)
- Callout: "No heartbeat on low-traffic databases is top production issue"
- Comparison table: pg_logical_emit_message vs heartbeat table approach

**Prior decisions to honor:**
- heartbeat.interval.ms = 10000 (10s for Aurora failover detection)
- max_slot_wal_keep_size mandatory (from Phase 6)

**Style:**
- Russian explanatory text, English SQL/config
- Builds on Phase 6 WAL content (explicit references)
- Frontmatter: title, description, order: 5, difficulty: intermediate, duration: 30min, topics: [wal-management, heartbeat, replication-slots, production]
  </action>
  <verify>
- File exists at src/content/course/03-module-3/05-wal-bloat-heartbeat.mdx
- `npm run build` passes without errors
- File contains heartbeat.action.query configuration
- File has 200+ lines
- File mentions pg_logical_emit_message
  </verify>
  <done>Students can configure heartbeat for slot advancement, understand multi-layer WAL defense, and monitor slot health with appropriate alerting thresholds</done>
</task>

<task type="auto">
  <name>Task 2: Create Connector Scaling and Tasks lesson</name>
  <files>src/content/course/03-module-3/06-connector-scaling-tasks.mdx</files>
  <action>
Create myth-busting lesson on Debezium connector scaling (MOD3-06):

**Structure:**
1. The Myth: "Set tasks.max=4 to scale PostgreSQL connector"
   - Reality: PostgreSQL connector ONLY supports tasks.max=1
   - Why: WAL is sequential, one reader must process in order
   - Contrast with: SQL Server, MongoDB which support multiple tasks
2. Why PostgreSQL is single-task:
   - WAL architecture explanation (sequential log)
   - Logical decoding position tracking
   - No natural partition boundary like shards or databases
3. Actual scaling strategies:
   - Strategy 1: Multiple connectors for different table sets
     - table.include.list per connector
     - Different topic.prefix for isolation
     - Use case: Independent consumers for different domains
   - Strategy 2: Downstream parallelization
     - Single connector -> Kafka topic with N partitions
     - N consumer instances process in parallel
     - Partitioning by key for ordering guarantees
   - Strategy 3: Performance tuning (single connector)
     - max.queue.size: 16384 (double default)
     - max.batch.size: 4096 (increase batch)
     - poll.interval.ms: 500 (reduce poll interval)
4. Performance ceiling:
   - Single PostgreSQL connector: ~7,000 events/second optimal
   - Beyond this: architectural changes required
5. When to use which strategy (decision framework)

**Include:**
- Mermaid diagram: Single-task vs multi-connector architecture
- Mermaid diagram: Downstream parallelization pattern
- Warning callout: "tasks.max > 1 has NO EFFECT on PostgreSQL connector"
- Performance tuning config example with comments
- Comparison table: Scaling strategies with pros/cons

**Teaching emphasis:**
- Explicitly bust the tasks.max myth (common misconception)
- Provide actionable alternatives
- Show when each strategy is appropriate

**Style:**
- Russian explanatory text, English config/architecture terms
- Direct, myth-busting tone
- Frontmatter: title, description, order: 6, difficulty: advanced, duration: 25min, topics: [scaling, tasks, performance, architecture]
  </action>
  <verify>
- File exists at src/content/course/03-module-3/06-connector-scaling-tasks.mdx
- `npm run build` passes without errors
- File explicitly mentions tasks.max limitation
- File has 180+ lines
- File describes multiple scaling strategies
  </verify>
  <done>Students understand single-task limitation for PostgreSQL connector, know actual scaling strategies, and can make informed architecture decisions for high-throughput CDC</done>
</task>

<task type="auto">
  <name>Task 3: Create Disaster Recovery Procedures lesson</name>
  <files>src/content/course/03-module-3/07-disaster-recovery-procedures.mdx</files>
  <action>
Create comprehensive lesson on CDC disaster recovery procedures (MOD3-07):

**Structure:**
1. What can go wrong:
   - Kafka Connect crash (offsets in connect-offsets topic)
   - Connector deletion (offsets preserved, slot may be orphaned)
   - Database failover (slot lost, covered in Phase 6 Aurora content)
   - Kafka cluster failure (offsets lost)
2. Understanding offset storage:
   - connect-offsets topic in Kafka
   - Key: connector name + partition info
   - Value: LSN position in PostgreSQL WAL
3. Offset backup procedures:
   - Option 1: kafka-console-consumer to file
     - kafka-console-consumer --topic connect-offsets --from-beginning
     - Captures all keys and values
   - Option 2: kafka-backup tool (comprehensive)
   - Frequency: Based on RPO (Recovery Point Objective)
4. Offset restoration (Kafka Connect 3.6+):
   - REST API endpoints for offset management
   - GET /connectors/{name}/offsets
   - PATCH /connectors/{name}/offsets (requires stopped connector)
   - Step-by-step restoration procedure
5. Slot recreation after failure:
   - Check for orphaned slots (active=false with large retained_wal)
   - Safe cleanup: pg_drop_replication_slot() only after confirming connector removed
   - Data loss risk: New slot starts from current position
6. DR drill procedure:
   - Stop connector
   - Backup offsets
   - Delete connector
   - Restore from backup
   - Verify no data loss
7. Runbook template for production DR

**Include:**
- Mermaid diagram: Offset flow (Connector -> Kafka topic offset -> connect-offsets -> restoration)
- Complete offset backup script (bash)
- REST API examples for offset management (curl commands)
- SQL for orphaned slot detection and cleanup
- Callout: "Test DR regularly - untested DR is no DR"
- Lab exercise: Simulate connector failure, restore from backup, verify recovery

**Prior knowledge references:**
- Link to Phase 6 Aurora failover content
- Link to Phase 6 replication slot lifecycle content

**Style:**
- Russian explanatory text, English commands/scripts
- Runbook format with numbered steps
- Frontmatter: title, description, order: 7, difficulty: advanced, duration: 40min, topics: [disaster-recovery, offsets, backup, runbooks]
  </action>
  <verify>
- File exists at src/content/course/03-module-3/07-disaster-recovery-procedures.mdx
- `npm run build` passes without errors
- File contains offset backup commands
- File has 200+ lines
- File mentions REST API for offset management
  </verify>
  <done>Students can execute offset backup procedures, restore connector state after failure, handle orphaned slots, and have runbook template for production DR</done>
</task>

</tasks>

<verification>
After all tasks complete:
1. Three lesson files exist in src/content/course/03-module-3/ (05-, 06-, 07-)
2. `npm run build` passes without errors
3. Each file has proper frontmatter with order, difficulty, duration
4. Heartbeat configuration is complete and accurate
5. Single-task limitation is clearly explained
6. DR procedures are step-by-step actionable
7. Content links to Phase 6 where appropriate
</verification>

<success_criteria>
- 3 MDX files created in src/content/course/03-module-3/
- Total 580+ lines across all three files
- 4+ Mermaid diagrams total
- All files pass content collection validation
- Build completes without errors
- Runbook-style procedures are copy-paste ready
- Single-task myth explicitly busted
</success_criteria>

<output>
After completion, create `.planning/phases/07-module-3-production-operations/07-03-SUMMARY.md`
</output>
