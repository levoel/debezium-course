---
phase: 10-module-6-cloud-native-gcp
plan: 03
type: execute
wave: 2
depends_on: ["10-01", "10-02"]
files_modified:
  - src/content/course/06-module-6/05-cloud-run-event-driven.mdx
  - src/content/course/06-module-6/06-cloud-monitoring.mdx
autonomous: true

must_haves:
  truths:
    - "Students can deploy Cloud Run service triggered by Pub/Sub CDC events"
    - "Students can monitor end-to-end CDC pipeline in Cloud Monitoring"
    - "Students understand event-driven CDC processing patterns"
  artifacts:
    - path: "src/content/course/06-module-6/05-cloud-run-event-driven.mdx"
      provides: "Cloud Run event-driven CDC processing lesson"
      contains: "google.cloud.pubsub.topic.v1.messagePublished"
    - path: "src/content/course/06-module-6/06-cloud-monitoring.mdx"
      provides: "Cloud Monitoring for CDC pipeline lesson"
      contains: "custom.googleapis.com/debezium"
  key_links:
    - from: "lesson-05"
      to: "Pub/Sub topics"
      via: "Eventarc triggers on CDC topic messages"
      pattern: "eventarc triggers create"
    - from: "lesson-06"
      to: "all prior lessons"
      via: "Monitoring covers Cloud SQL, Debezium, Pub/Sub, Dataflow, Cloud Run"
      pattern: "replication_slots|MilliSecondsBehindSource"
---

<objective>
Create lessons covering event-driven CDC processing with Cloud Run and end-to-end pipeline monitoring.

Purpose: Complete the Module 6 content with serverless event handling and comprehensive observability. Cloud Run enables custom business logic per CDC event, while Cloud Monitoring provides visibility across all pipeline components.

Output: Two MDX lessons teaching Cloud Run event-driven CDC processing and end-to-end monitoring across the entire GCP CDC pipeline.
</objective>

<execution_context>
@/Users/levoely/.claude/get-shit-done/workflows/execute-plan.md
@/Users/levoely/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/10-module-6-cloud-native-gcp/10-RESEARCH.md

Reference for content patterns:
@src/content/course/05-module-5/01-advanced-python-consumer.mdx
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Cloud Run Event-Driven Processing lesson</name>
  <files>src/content/course/06-module-6/05-cloud-run-event-driven.mdx</files>
  <action>
Create MDX lesson covering Cloud Run for event-driven CDC processing.

**Frontmatter:**
```yaml
title: "Cloud Run для Event-Driven CDC"
description: "Serverless обработка CDC событий: Cloud Run + Eventarc триггеры на Pub/Sub"
order: 5
difficulty: "intermediate"
estimatedTime: 40
topics: ["Cloud Run", "Eventarc", "Pub/Sub", "Serverless", "Event-Driven"]
prerequisites: ["module-6/02-debezium-server-pubsub", "module-6/03-iam-workload-identity"]
```

**Content structure:**

1. **Introduction** - When to use Cloud Run for CDC
   - Use cases: custom business logic, notifications, index updates, cache invalidation
   - Comparison: Dataflow (batch analytics) vs Cloud Run (per-event actions)
   - Architecture: Pub/Sub -> Eventarc -> Cloud Run
   - Mermaid diagram showing event flow

2. **Cloud Run Service Structure**
   - Python Flask handler from research:
     ```python
     from flask import Flask, request
     import base64
     import json

     app = Flask(__name__)

     @app.route("/", methods=["POST"])
     def handle_cdc_event():
         envelope = request.get_json()

         if not envelope or "message" not in envelope:
             return "Bad Request", 400

         pubsub_message = envelope["message"]

         if "data" in pubsub_message:
             data = base64.b64decode(pubsub_message["data"]).decode("utf-8")
             event = json.loads(data)

             # Debezium event structure
             operation = event.get("op")  # c, u, d, r
             before = event.get("before")
             after = event.get("after")
             source = event.get("source", {})

             table = source.get("table")

             # Business logic
             if operation == "c" and table == "orders":
                 send_order_notification(after)
             elif operation == "u" and table == "customers":
                 update_search_index(after)

             return ("", 204)

         return ("Bad Request", 400)
     ```
   - Explain each section with Russian comments

3. **Dockerfile for Cloud Run**
   ```dockerfile
   FROM python:3.11-slim

   WORKDIR /app
   COPY requirements.txt .
   RUN pip install --no-cache-dir -r requirements.txt

   COPY main.py .

   CMD ["gunicorn", "--bind", ":8080", "main:app"]
   ```
   - requirements.txt: Flask, gunicorn

4. **Deploying to Cloud Run**
   - Build and push:
     ```bash
     gcloud builds submit --tag gcr.io/PROJECT_ID/cdc-processor

     gcloud run deploy cdc-processor \
       --image gcr.io/PROJECT_ID/cdc-processor \
       --region us-central1 \
       --service-account=cdc-processor-sa@PROJECT_ID.iam.gserviceaccount.com \
       --no-allow-unauthenticated
     ```

5. **Creating Eventarc Trigger**
   - Trigger command:
     ```bash
     gcloud eventarc triggers create cdc-order-processor \
       --location=us-central1 \
       --destination-run-service=cdc-processor \
       --destination-run-region=us-central1 \
       --event-filters="type=google.cloud.pubsub.topic.v1.messagePublished" \
       --transport-topic=projects/PROJECT_ID/topics/cdc.public.orders
     ```
   - Grant invoker role to Eventarc service account

6. **Handling Multiple Tables**
   - Option 1: Separate triggers per topic (recommended)
   - Option 2: Single handler with table routing
   - Code example for table routing

7. **Error Handling and Retries**
   - Pub/Sub retry behavior on non-2xx response
   - Designing idempotent handlers
   - Dead letter queue configuration
   - Logging for debugging:
     ```python
     import google.cloud.logging
     client = google.cloud.logging.Client()
     client.setup_logging()
     ```

8. **Practical Examples**
   - Send Slack notification on new order
   - Update Elasticsearch index on customer change
   - Invalidate Redis cache on product update
   - Brief code snippets for each

9. **Scaling and Concurrency**
   - Cloud Run auto-scaling based on request volume
   - Concurrency settings for CDC workloads
   - Cold start considerations for low-traffic tables

Include Mermaid sequence diagram: Pub/Sub message -> Eventarc -> Cloud Run -> External service
  </action>
  <verify>
File exists at src/content/course/06-module-6/05-cloud-run-event-driven.mdx
Content includes Flask handler with Debezium event parsing
Content includes gcloud eventarc triggers create command
Content includes Dockerfile
Content includes error handling and idempotency guidance
Frontmatter has all required fields
  </verify>
  <done>
Lesson covers Cloud Run event-driven CDC processing with complete Python handler, Eventarc trigger setup, and practical use case examples.
  </done>
</task>

<task type="auto">
  <name>Task 2: Create Cloud Monitoring lesson</name>
  <files>src/content/course/06-module-6/06-cloud-monitoring.mdx</files>
  <action>
Create MDX lesson covering end-to-end CDC pipeline monitoring in Cloud Monitoring.

**Frontmatter:**
```yaml
title: "End-to-End Мониторинг CDC Pipeline"
description: "Cloud Monitoring для всех компонентов: Cloud SQL, Debezium, Pub/Sub, Dataflow, Cloud Run"
order: 6
difficulty: "advanced"
estimatedTime: 45
topics: ["Cloud Monitoring", "Alerting", "Metrics", "Dashboards", "SRE"]
prerequisites: ["module-6/01-cloud-sql-setup", "module-6/02-debezium-server-pubsub", "module-6/04-dataflow-bigquery", "module-6/05-cloud-run-event-driven"]
```

**Content structure:**

1. **Introduction** - Observability for CDC pipelines
   - Why monitoring is critical for CDC (data integrity, SLOs)
   - Components to monitor: Source DB, CDC engine, messaging, consumers
   - Mermaid diagram: monitoring points in pipeline
   - Reference Module 3 Prometheus/Grafana concepts

2. **Cloud SQL PostgreSQL Monitoring**
   - Built-in metrics:
     - `cloudsql.googleapis.com/database/cpu/utilization`
     - `cloudsql.googleapis.com/database/disk/utilization`
     - `cloudsql.googleapis.com/database/postgresql/num_backends`
   - Replication slot monitoring (custom query in Cloud SQL Insights):
     ```sql
     SELECT slot_name, active,
       pg_size_pretty(pg_wal_lsn_diff(pg_current_wal_lsn(), confirmed_flush_lsn)) AS lag
     FROM pg_replication_slots;
     ```
   - Alert: disk utilization > 80% (WAL bloat indicator)

3. **Debezium Server Metrics**
   - JMX metrics exposed via Prometheus exporter
   - Key metrics:
     - `MilliSecondsBehindSource` (lag)
     - `QueueRemainingCapacity` (backpressure)
     - `TotalNumberOfEventsSeen` (throughput)
   - GKE integration: Google Cloud Managed Service for Prometheus
   - Custom metric export to Cloud Monitoring:
     ```yaml
     # PodMonitoring CRD for GKE
     apiVersion: monitoring.googleapis.com/v1
     kind: PodMonitoring
     metadata:
       name: debezium-server
     spec:
       selector:
         matchLabels:
           app: debezium-server
       endpoints:
       - port: metrics
         interval: 30s
     ```

4. **Pub/Sub Metrics**
   - Built-in metrics:
     - `pubsub.googleapis.com/subscription/oldest_unacked_message_age`
     - `pubsub.googleapis.com/subscription/num_undelivered_messages`
     - `pubsub.googleapis.com/topic/send_message_operation_count`
   - Alert thresholds:
     - oldest_unacked_message_age > 300s (5 min backlog)
     - dead_letter_message_count > 0 (processing failures)

5. **Dataflow Metrics**
   - Built-in metrics:
     - `dataflow.googleapis.com/job/system_lag`
     - `dataflow.googleapis.com/job/elements_produced_count`
     - `dataflow.googleapis.com/job/current_num_vcpus`
   - Alert: system_lag > 60s
   - Cost monitoring: vCPU hours

6. **Cloud Run Metrics**
   - Built-in metrics:
     - `run.googleapis.com/request_count`
     - `run.googleapis.com/request_latencies`
     - `run.googleapis.com/container/instance_count`
   - Error rate monitoring: 5xx responses

7. **Creating Unified Dashboard**
   - Dashboard structure:
     - Top row: High-level health (green/red indicators)
     - Row 2: Source metrics (Cloud SQL CPU, connections, WAL)
     - Row 3: CDC engine (Debezium lag, throughput)
     - Row 4: Messaging (Pub/Sub backlog, DLQ)
     - Row 5: Consumers (Dataflow lag, Cloud Run errors)
   - JSON dashboard definition excerpt (for import)
   - Mermaid diagram of dashboard layout

8. **Alerting Policies**
   - Complete alert policy YAML from research:
     ```yaml
     displayName: "CDC Pipeline - Debezium Lag High"
     conditions:
       - displayName: "Lag > 60 seconds"
         conditionThreshold:
           filter: |
             resource.type="k8s_pod"
             metric.type="custom.googleapis.com/debezium/milliseconds_behind_source"
           comparison: COMPARISON_GT
           thresholdValue: 60000
           duration: 300s
     notificationChannels:
       - projects/PROJECT/notificationChannels/email-oncall
     ```
   - Alert hierarchy: critical (pages) vs warning (email)

9. **Runbooks**
   - High replication lag:
     1. Check Cloud SQL CPU/memory
     2. Query pg_replication_slots
     3. Check Debezium Server logs
     4. Verify Pub/Sub publish throughput
   - Pub/Sub backlog growing:
     1. Check Cloud Run error rate
     2. Check Dataflow worker health
     3. Review dead letter queue

10. **Cost Optimization**
    - Metrics sampling (30s vs 60s)
    - Log exclusion filters for verbose Debezium logs
    - Alert aggregation to prevent noise

Include Mermaid diagram showing: All pipeline components with monitoring points highlighted
  </action>
  <verify>
File exists at src/content/course/06-module-6/06-cloud-monitoring.mdx
Content includes metrics for all components (Cloud SQL, Debezium, Pub/Sub, Dataflow, Cloud Run)
Content includes alerting policy YAML
Content includes dashboard structure guidance
Content includes runbook examples
Frontmatter has all required fields
  </verify>
  <done>
Lesson covers comprehensive end-to-end CDC monitoring with metrics for all components, alerting policies, dashboard design, and operational runbooks.
  </done>
</task>

</tasks>

<verification>
- Both lessons created in src/content/course/06-module-6/ directory
- Lesson 05 covers Cloud Run + Eventarc event-driven processing (MOD6-05)
- Lesson 06 covers end-to-end monitoring across all components (MOD6-06)
- Prerequisites correctly chain to prior lessons
- All 6 requirements (MOD6-01 through MOD6-06) covered across the three plans
- Research patterns incorporated: Flask handler, Eventarc trigger, alert policies
</verification>

<success_criteria>
- MOD6-05 requirement covered by lesson 05 (Cloud Run for event-driven CDC processing)
- MOD6-06 requirement covered by lesson 06 (End-to-end monitoring in Cloud Monitoring)
- Students can deploy Cloud Run services triggered by CDC events
- Students can set up comprehensive monitoring across the entire pipeline
- All Phase 10 requirements complete
</success_criteria>

<output>
After completion, create `.planning/phases/10-module-6-cloud-native-gcp/10-03-SUMMARY.md`
</output>
