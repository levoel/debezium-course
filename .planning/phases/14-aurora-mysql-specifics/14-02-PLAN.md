---
phase: 14-aurora-mysql-specifics
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - src/content/course/08-module-8/08-enhanced-binlog-architecture.mdx
autonomous: true

must_haves:
  truths:
    - "Learner understands Aurora Enhanced Binlog architecture (storage nodes, parallel writes)"
    - "Learner can evaluate 99% recovery improvement and 13% compute overhead claims"
    - "Learner knows Enhanced Binlog limitations (backtrack incompatibility, not in backups, no Global Database replication)"
    - "Learner can decide when to enable Enhanced Binlog vs standard binlog"
  artifacts:
    - path: "src/content/course/08-module-8/08-enhanced-binlog-architecture.mdx"
      provides: "Aurora Enhanced Binlog architecture lesson"
      min_lines: 450
      contains: ["aurora_enhanced_binlog", "storage nodes", "binlog_backup = 0"]
  key_links:
    - from: "08-enhanced-binlog-architecture.mdx"
      to: "Phase 12 binlog architecture (01)"
      via: "builds on binlog fundamentals"
      pattern: "Модуль.*binlog"
---

<objective>
Create comprehensive Aurora Enhanced Binlog architecture lesson covering storage-level optimization, performance claims, critical limitations, and decision criteria.

Purpose: MYSQL-08 requires understanding of Aurora Enhanced Binlog introduced in Aurora MySQL 3.03.1+. This lesson teaches learners the architectural innovation and its trade-offs for CDC workloads.

Output: `src/content/course/08-module-8/08-enhanced-binlog-architecture.mdx` with complete Enhanced Binlog deep dive
</objective>

<execution_context>
@/Users/levoely/.claude/get-shit-done/workflows/execute-plan.md
@/Users/levoely/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/14-aurora-mysql-specifics/14-RESEARCH.md
@src/content/course/08-module-8/01-binlog-architecture.mdx
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Enhanced Binlog architecture lesson</name>
  <files>src/content/course/08-module-8/08-enhanced-binlog-architecture.mdx</files>
  <action>
Create lesson file with frontmatter:
- title: "Aurora Enhanced Binlog: Архитектура и Trade-offs"
- order: 8
- difficulty: advanced
- estimatedTime: 30 minutes
- topics: aurora-mysql, enhanced-binlog, aws, performance, cdc
- prerequisites: module-8/07-aurora-parameter-groups

Content structure (Russian text, English code):

1. **Introduction** - Why Aurora reimagined binlog
   - Traditional binlog: sequential writes (transaction log, then binlog)
   - Aurora MySQL 3.03.1+ innovation: parallel writes to specialized storage
   - What this means for CDC: same binlog protocol, different storage backend

2. **Standard Binlog Architecture** (baseline, reference Lesson 01)
   - MySQL engine writes to redo log → commit → binlog file
   - Single storage path, sequential operations
   - Compute overhead ~50% for binlog-heavy workloads
   - Brief Mermaid diagram showing sequential flow

3. **Enhanced Binlog Architecture** (key innovation)
   - Parallel writes: transaction log AND binlog simultaneously
   - Specialized storage nodes for binlog (sorting/ordering at storage layer)
   - Engine sends unsorted binlog events → storage nodes reorder
   - Mermaid diagram showing parallel paths (from research)
   - Note: Debezium reads via standard MySQL protocol (no connector changes needed)

4. **Performance Claims Analysis** (AWS official numbers)
   - 99% faster recovery after restart/failover
   - Compute overhead: 50% → 13%
   - 40% throughput increase on highly concurrent workloads
   - CloudWatch metrics: ChangeLogBytesUsed, ChangeLogReadIOPs, ChangeLogWriteIOPs
   - Note callout: Claims from AWS blog, not independently benchmarked

5. **Critical Limitations** (MUST understand before enabling)
   - **Backtrack incompatibility**: Cannot enable if cluster EVER had backtrack (even if disabled)
   - **Not in backups**: Enhanced binlog files NOT included in Aurora snapshots/clones
   - **Global Database**: Binlog NOT replicated to secondary regions
   - **max_binlog_size**: Auto-changed to 256MB (read-only)
   - Danger callout: These limitations are permanent decisions

6. **Enabling Enhanced Binlog** (hands-on)
   - Prerequisites check (AURORA_VERSION() >= 3.03.1)
   - Parameter group settings:
     - aurora_enhanced_binlog = 1
     - binlog_format = ROW (not OFF)
     - binlog_backup = 0 (MUST disable)
     - binlog_replication_globaldb = 0 (MUST disable)
   - Reboot requirement
   - Verification: SHOW STATUS LIKE 'aurora_enhanced_binlog' (ACTIVE)

7. **Disabling Enhanced Binlog** (if needed)
   - Reverse parameter changes
   - New binlog sequence starts from .000001
   - Warning: Debezium offset will need resnapshot

8. **Decision Matrix: Enhanced vs Standard Binlog** (table)
   | Use Case | Enhanced Binlog? | Rationale |
   | High write throughput, production | Yes | 13% overhead vs 50% |
   | Need backtrack for point-in-time testing | No | Incompatible |
   | Aurora Global Database | No | No cross-region replication |
   | Need binlog in backups for DR | No | Not in backups |
   | Standard workload, simplicity preferred | No | Simpler setup |

9. **Impact on CDC** (specifically for Debezium)
   - No connector configuration changes required
   - Read performance likely unchanged (standard protocol)
   - Primary benefits: faster Aurora recovery, lower compute overhead
   - After Aurora restore/clone: binlog starts fresh, need resnapshot

10. **Key Takeaways** (6-8 bullet points)

11. **What's Next** (preview snapshot modes for Aurora)

Use Mermaid for:
- Standard binlog sequential flow (Engine -> Redo -> Commit -> Binlog file)
- Enhanced Binlog parallel flow (Engine -> parallel to [Redo | Storage nodes] -> Ordered binlog)
- Decision flowchart (Need backtrack? -> No -> Need Global DB? -> No -> High writes? -> Yes -> Enhanced Binlog)

Use Callout components:
- type="danger" for backtrack incompatibility (permanent decision)
- type="warning" for not in backups, Global Database limitations
- type="note" for performance claims context
- type="tip" for verification commands
  </action>
  <verify>
```bash
# File exists with substantial content
wc -l src/content/course/08-module-8/08-enhanced-binlog-architecture.mdx
# Expected: 450+ lines

# Contains Enhanced Binlog configuration
grep -c "aurora_enhanced_binlog" src/content/course/08-module-8/08-enhanced-binlog-architecture.mdx

# Contains storage nodes concept
grep -c "storage nodes" src/content/course/08-module-8/08-enhanced-binlog-architecture.mdx

# Contains required parameter settings
grep "binlog_backup = 0" src/content/course/08-module-8/08-enhanced-binlog-architecture.mdx
```
  </verify>
  <done>Lesson covers: Enhanced Binlog architecture, performance claims, critical limitations, enable/disable procedures, decision matrix. Learner can evaluate when to use Enhanced Binlog.</done>
</task>

</tasks>

<verification>
```bash
# Lesson file exists and has proper frontmatter
head -20 src/content/course/08-module-8/08-enhanced-binlog-architecture.mdx | grep -E "^(title|order|difficulty):"

# Minimum content depth
wc -l src/content/course/08-module-8/08-enhanced-binlog-architecture.mdx

# Build passes (Astro can process MDX)
cd /Users/levoely/debezium\ course && npm run build 2>&1 | tail -5
```
</verification>

<success_criteria>
- Lesson file exists at src/content/course/08-module-8/08-enhanced-binlog-architecture.mdx
- Content is 450+ lines covering all sections
- Contains Enhanced Binlog parameter configuration
- Contains storage nodes architecture explanation
- Contains decision matrix for when to use Enhanced Binlog
- Contains critical limitations (backtrack, backups, Global Database)
- Build passes without errors
</success_criteria>

<output>
After completion, create `.planning/phases/14-aurora-mysql-specifics/14-02-SUMMARY.md`
</output>
