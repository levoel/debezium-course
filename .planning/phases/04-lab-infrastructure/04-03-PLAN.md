---
phase: 04-lab-infrastructure
plan: 03
type: execute
wave: 1
depends_on: []
files_modified:
  - labs/jupyter/Dockerfile
  - labs/jupyter/requirements.txt
  - labs/notebooks/01-setup-verification.ipynb
autonomous: true

must_haves:
  truths:
    - "JupyterLab runs with Python 3.11+ and confluent-kafka library"
    - "Students can connect to Kafka from notebook"
    - "Sample notebook verifies lab environment setup"
  artifacts:
    - path: "labs/jupyter/Dockerfile"
      provides: "Custom JupyterLab image with Kafka client"
      contains: "confluent-kafka"
    - path: "labs/jupyter/requirements.txt"
      provides: "Python dependencies for CDC exercises"
      contains: "confluent-kafka"
    - path: "labs/notebooks/01-setup-verification.ipynb"
      provides: "Environment verification notebook"
      contains: "KafkaConsumer"
  key_links:
    - from: "labs/jupyter/Dockerfile"
      to: "labs/jupyter/requirements.txt"
      via: "pip install requirements"
      pattern: "requirements.txt"
    - from: "labs/notebooks/01-setup-verification.ipynb"
      to: "kafka:9092"
      via: "Kafka consumer connection"
      pattern: "bootstrap.servers"
---

<objective>
Create the JupyterLab environment with Python dependencies for consuming and processing CDC events.

Purpose: Provide students an interactive Python environment for hands-on CDC exercises.
Output: Custom JupyterLab Docker image and setup verification notebook.
</objective>

<execution_context>
@/Users/levoely/.claude/get-shit-done/workflows/execute-plan.md
@/Users/levoely/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/04-lab-infrastructure/04-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Python requirements file</name>
  <files>labs/jupyter/requirements.txt</files>
  <action>
Create labs/jupyter/requirements.txt with all Python dependencies for CDC exercises.

Research confirmed: confluent-kafka 2.13.0+ has ARM64 wheels available on PyPI.

```
# Debezium Lab Python Dependencies
# All packages verified for ARM64 compatibility

# Kafka client (native ARM64 wheels available)
confluent-kafka>=2.13.0

# Data processing
pandas>=2.0.0
numpy>=1.24.0

# JSON/Avro handling
fastavro>=1.9.0
jsonschema>=4.0.0

# HTTP client for Connect REST API
requests>=2.31.0

# Database connectivity (for direct PostgreSQL access in exercises)
psycopg2-binary>=2.9.9

# Jupyter utilities
ipywidgets>=8.0.0
tqdm>=4.65.0
```

Note: psycopg2-binary is needed for some exercises that query PostgreSQL directly.
fastavro is for working with Avro-encoded messages from Schema Registry.
  </action>
  <verify>File exists at labs/jupyter/requirements.txt with confluent-kafka>=2.13.0</verify>
  <done>Requirements file contains all CDC exercise dependencies with version constraints</done>
</task>

<task type="auto">
  <name>Task 2: Create JupyterLab Dockerfile</name>
  <files>labs/jupyter/Dockerfile</files>
  <action>
Create labs/jupyter/Dockerfile extending jupyter/scipy-notebook with CDC dependencies.

Research finding: jupyter/scipy-notebook does NOT include confluent-kafka by default, so custom Dockerfile is required.

```dockerfile
# JupyterLab for Debezium CDC Labs
# Extends official Jupyter image with Kafka client and data engineering libraries

FROM jupyter/scipy-notebook:latest

LABEL maintainer="Debezium Course"
LABEL description="JupyterLab environment for CDC exercises"

# Install additional Python packages as user (not root)
COPY --chown=${NB_UID}:${NB_GID} requirements.txt /tmp/requirements.txt
RUN pip install --no-cache-dir -r /tmp/requirements.txt

# Set working directory to mounted notebooks volume
WORKDIR /home/jovyan/work

# Expose JupyterLab port
EXPOSE 8888

# Default command (can be overridden)
CMD ["start-notebook.sh", "--NotebookApp.token=''", "--NotebookApp.password=''"]
```

Key decisions:
- Use jupyter/scipy-notebook as base (includes pandas, numpy, matplotlib already)
- Copy requirements as user to avoid permission issues (research pitfall #5)
- Disable token/password for easier lab access (development environment only)
- WORKDIR set to /home/jovyan/work which will be volume-mounted to ./notebooks
  </action>
  <verify>File exists at labs/jupyter/Dockerfile with FROM jupyter/scipy-notebook and COPY requirements.txt</verify>
  <done>Dockerfile extends scipy-notebook with CDC dependencies, builds without errors</done>
</task>

<task type="auto">
  <name>Task 3: Create setup verification notebook</name>
  <files>labs/notebooks/01-setup-verification.ipynb</files>
  <action>
Create labs/notebooks/01-setup-verification.ipynb that students run to verify their lab environment.

Use Jupyter notebook JSON format (.ipynb). The notebook should:

1. **Cell 1 (Markdown):** Title and introduction
   - "# Lab Environment Verification"
   - Explain what this notebook tests

2. **Cell 2 (Code):** Check Python version
   ```python
   import sys
   print(f"Python version: {sys.version}")
   assert sys.version_info >= (3, 11), "Python 3.11+ required"
   print("Python version OK")
   ```

3. **Cell 3 (Code):** Check required packages
   ```python
   import confluent_kafka
   import pandas as pd
   import psycopg2
   import fastavro
   import requests

   print(f"confluent-kafka: {confluent_kafka.version()}")
   print(f"pandas: {pd.__version__}")
   print("All packages imported successfully")
   ```

4. **Cell 4 (Code):** Test PostgreSQL connection
   ```python
   import psycopg2

   conn = psycopg2.connect(
       host="postgres",
       port=5432,
       database="inventory",
       user="postgres",
       password="postgres"
   )
   cur = conn.cursor()
   cur.execute("SELECT COUNT(*) FROM customers")
   count = cur.fetchone()[0]
   print(f"PostgreSQL connection OK - {count} customers in database")
   conn.close()
   ```

5. **Cell 5 (Code):** Test Kafka connection
   ```python
   from confluent_kafka.admin import AdminClient

   admin = AdminClient({'bootstrap.servers': 'kafka:9092'})
   topics = admin.list_topics(timeout=10)
   print(f"Kafka connection OK - {len(topics.topics)} topics available")
   print("Topics:", list(topics.topics.keys())[:5])  # Show first 5
   ```

6. **Cell 6 (Code):** Test Connect REST API
   ```python
   import requests

   response = requests.get('http://connect:8083/')
   data = response.json()
   print(f"Kafka Connect version: {data['version']}")
   print(f"Commit: {data['commit']}")

   connectors = requests.get('http://connect:8083/connectors').json()
   print(f"Active connectors: {connectors}")
   ```

7. **Cell 7 (Markdown):** Success message
   - "## All checks passed! Your lab environment is ready."

Create valid .ipynb JSON with proper cell structure, metadata, and kernel spec for Python 3.
  </action>
  <verify>
File exists and is valid Jupyter notebook:
`cat labs/notebooks/01-setup-verification.ipynb | jq '.cells | length'`
Expected: 7 (or more cells)
  </verify>
  <done>Setup verification notebook tests Python, packages, PostgreSQL, Kafka, and Connect connectivity</done>
</task>

</tasks>

<verification>
After all tasks complete, verify JupyterLab configuration:

```bash
cd labs

# Verify Dockerfile syntax
docker build -t debezium-lab-jupyter -f jupyter/Dockerfile jupyter/

# Check requirements file
cat jupyter/requirements.txt

# Validate notebook JSON
cat notebooks/01-setup-verification.ipynb | jq .nbformat
# Expected: 4

# Check notebook has cells
cat notebooks/01-setup-verification.ipynb | jq '.cells | length'
# Expected: 7 or more
```

Expected directory structure:
```
jupyter/
  Dockerfile
  requirements.txt
notebooks/
  01-setup-verification.ipynb
```
</verification>

<success_criteria>
1. Dockerfile builds successfully with `docker build` (no errors)
2. requirements.txt includes confluent-kafka>=2.13.0, pandas, psycopg2-binary
3. Notebook JSON is valid with nbformat: 4
4. Notebook contains cells testing Python version, package imports, PostgreSQL, Kafka, Connect
5. All internal service references use Docker network names (postgres, kafka, connect)
</success_criteria>

<output>
After completion, create `.planning/phases/04-lab-infrastructure/04-03-SUMMARY.md`
</output>
